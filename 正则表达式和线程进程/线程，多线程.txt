一，threading模块的属性和方法：

    current_thread()返回当前线程对象
    main_thread() 返回主线程对象
    active_count() 当前出于活着的线程 (包含主线程)
    enumerate() 返回所有活着的线程列表，只包括开始的线程 (包含主线程)
    get_ident() 返回当前线程的id，是一个非0的整数

	thread类：
		1,创建一个线程实例：threading.Thread(target=函数名，name='线程名'，args=(位置参数), kwargs={关键字参数}, daemon=None)  注意：关键字参数传参时
		变量要用字符串
		2,实例属性，方法 name属性获取线程名，getName()方法获取线程名，setName()方法设置线程名
			          ident 返回线程ID，线程启动才有ID，否者为none。线程退出ID依旧可以访问，线程ID可以重复利用
			          is_alive() 可以判断线程是否还活着
			          start() 方法启动一个线程，start只能用一次，start会调用run()方法，run()方法运行的是run函数。只有start能启动多线程
		threading.Timer类：
			          threading.Timer 这是Thread的子类，这个类可以定义一个定时器函数，延时执行
			          threading.Timer(interval, function, args=None, kwargs=None) -> interval 传延迟时长，function -> 传绑定函数名，args用列表传参
			          start执行后，Timer处于等待状态，等待了interval秒后，执行function函数
	threading.local类：
		这是一个线程类，用法就是创建一个实例，如：t = threading.local()  得到一个local类实例对象，这个类对象可以得到一个全局对象，然后多线程都可以用这个全局
		对象互不干扰

	Event类： 线程同步问题
		set() 标记设置为True， clear() 标记设置为Flase， is_set() 判断标记是否为True， wait(timeout=None)
		event事件就是一种信号，信号为True就执行。
		wait 等待函数，等到了就返回True,等不到就返回Flase. timeout是设置等待时长，这里的等待并不是等timeout的时间，而是等event变成True的时间。

	Lock类：  锁的应用场景，凡是存在共享资源争抢的环境下都可以使用锁。适用于访问和修改同一个共享资源。一旦某个线程获得了锁，那么试图获得锁的其他线程将会被阻塞。
		1.Lock有两个用法：
		Lock().acquire(blocking=True，timeout=-1) 获得锁，成功返回True。默认情况下是阻塞的，在阻塞情况下可以设置超时时长timeout，timeout=-1表示永久阻塞。
		blocking=Flase时为非阻塞模式，这时是禁止设置timeout的。
		Lock().release() 释放锁。释放锁可以在任意的线程中调用。未上锁的情况下调用release时会抛RuntimeError异常。
		使用方法：
		线程并行 --> Lock().acquire()(获得锁)  -->  线程内的处理逻辑块(线程串行)  --> Lock().release()(释放锁)  --> 线程并行

		2.加锁和减锁如果操作不当是会产生死锁情况的，为了避免死锁出现，一般会使用上下文语句进行管理，try...finally的结构
		锁在使用时最好是注意这么几点：
					(1)少用锁，因为使用锁多线程在访问这个被锁资源时就变成了类似单线程的串行效果，效率低，要么排队要么争抢，有必要时再用。
					(2)一定要避免死锁，所以要用上下文管理的语句
					(3)上锁的时间越短越好，就好比交通拥堵一定是拥堵时间越短越通畅，另外不需要的锁要立即的释放。
		所以说锁该用的情况下一定要用，但是要知道在哪里用，并不是无节制的随便上锁

	Rlock类： Rlock是线程相关的锁，是可重入锁。使用的方法与Lock一样，但是这个锁是在线程内可以重复获取的，而且在线程内不会阻塞。比如在线程A中重复的获取5次锁
		这5次都不会阻塞，是在本线程内不阻塞，但是会阻塞其他线程，除非线程A释放完这5次锁。

	Condition类：Condition(lock=None) 默认是传入Rlock对象
		condition构造方法应用于生产者消费者模型中，用于解决生产者消费者速度匹配的问题，这个方法是一种异步的方法，采用了通知机制，非常的有效率。
		如果没有采用condition，那么生产者生产的数据，消费者是不知道的，就要一直主动的去查看，比较浪费资源，但是用了condition，生产者生产了数据，就
		会唤醒等待线程，而消费者是在等待的，给消费者发送消息，消费者开始干活。
		方法：
		acquire(*args)  获得锁，使用condition 必须要先获得锁
		wait(self, timeout=None)  无限等待或超时
		notify(n=1) 唤醒指定数目的等待线程，没有等待的线程就不做操作
		notify_all()  唤醒所有的等待线程
	例子。。。。。
		因为condition也是使用了锁机制，所以需要获得锁，释放锁，也要使用上下文管理，确保锁一定会被释放

	Barrier类：屏障，路障，道闸的意思，有这么几个使用方式：
		1. Barrier(parties, action=None, timeout=None) 创造barrier实例对象，parties是指定等待的数目，比如 Barrier(5) 表示这个屏障要等待足够的5个线程都就位之后，
		这个屏障才会消失，好比田径运动，5个人参赛，但凡不够5人那么其他人就要等第5个就位以后，比赛才能开始，也就是屏障才会撤销，线程继续往下运行。
		2. Barrier(5).n_waiting  返回的是当前在屏障中等待的线程数
		3. Barrier(5).wait(timeout=None) 等待通过线程，返回0到线程-1的整数，每个线程返回不同。如果wait设置了超时，并且超时发送了，Barrier处于broken状态
		4. Barrier(5).broken 判断屏障是否处于破碎状态，如果破碎返回True
		5. Barrier(5).abort()  这个方法会让屏障处于broken状态，那么在等待中的线程或者调用了等待方法的线程中就会抛出BrokenBarrierError异常，直到reset恢复为止
		6. Barrier(5).reset() 这个方法可以使broken状态的线程重新恢复成拦截在状态
	例子。。。
		Barrier的用法大体分为两大类，一种是设置屏障的方法，一种是遇到某种条件打破屏障的方法，在应用中Barrier多应用于并发初始化的时候，例如启动一个程序，
		需要做加载磁盘文件，缓存预热，初始化连接池等准备工作，这些工作都是并发的，每个线程负责一种，只有都做好了，程序才会继续向下执行，这时候就需要用
		Barrier设置屏障，在屏障内这些线程都要等待，快的等慢的，只有都准备好了，屏障才会撤销。
		但是假设数据库的连接失败，那么初始化工作就失败了，就需要用abort打破这个屏障，如果没有abort方法的话，所有线程都会等待那个已经失败的线程，初始化
		工作就被阻塞在了这里，无限等待中，有了abort方法，等待中的线程就会异常退出，这个阻塞就会消失了。

	Semaphore类：Semaphore信号量的使用方法：
		1. Semaphore(value=1) 构造一个信号量对象，value值就是信号量内部计数器的值，小于0时抛ValueError
		2. Semaphore.acquire(block=False, timeout=None)  获取信号量，计数器减1，当计数器为0时被阻塞，获取成功返回True
		3. Semaphore.release() 释放信号量，计数器加1

		BoundedSemaphore类，这个类是有界信号量，用法与Semaphore的使用方法一样，唯一的区别是，在Semaphore中，假设初始化信号量为3，如果没有获取直接
		释放那么计数器就加了1，变成了4，这就有问题了，因为初始化是3，结果变成了4，跟一开始的初始化不一样。但是在BoundedSemaphore中，信号量是有界的，
		如果超界了，释放的信号量比初始化多了就会抛出ValueError异常, BoundedSemaphore是Semaphore的子类。

		这个信号量的用法跟Lock是非常像的在信号量的内部维护着一个计数器，获取一次减一，为0的时候就出现了阻塞，需要释放信号量来结束阻塞。可以看出信号量
		与锁是很相似的，锁可以看做是一种特殊的信号量，锁只允许同一时间的一个线程占用资源，锁的计数器为1。而信号量是可以允许多个线程来访问这个共享资源的
		但也不是无限制，共享资源的数量是有限的，应用最多的就是连接池。
	连接池例子。。。

总结一下线程的使用方法，线程模块有5个方法，都是与线程的属性或者状态有关。线程范围内有8个类，关键词是锁的有4个类，Lock, Rlock, Condition, (Bounded)Semaphore,
Lock和Rlock 都是单纯的获取锁，需要注意的就是获取以后的释放问题，一定要释放掉，否则就是死锁，用到了上下文管理。然后为了解决线程提高效率问题，引用了Condition，里面
有唤醒机制，这样就避免了等待中的线程无限的去主动查看数据是否准备好，只需要等着被叫就可以了。然后还有Semaphore信号量，一种特殊的锁，或者说锁是一种特殊的信号量。
这四个类的方法都比较简单也有共性，基本上都要获取，释放。

关键词是等待的有2个类，Event， Barrier。Event的核心就是解决线程同步的问题，里面是一种信号机制，Event就是在等这个信号变成True的时间，等到了就变成True，就不在阻塞，
在Event().wait()里面设置的时间看似是阻塞时间，其实是Event信号变成True的时间，wait3秒就是3秒之后发送Ture的信号，这样就起到了阻塞的作用。Barrier的作用与Event不同，
Barrier并不是在等时间，而是在等个数，好比一场比赛，5个参赛方，但凡少了哪一个这场比赛都进行不下去，如果任意的一方没有出现那么就要无限的等待，现实生活中这种情况很好
解决，直接取消比赛就行了。但是在线程中并不可能说取消就取消，5个线程哪一个出错了没有准备好，其他4个都会一直等下去，所以要有abort方法来打破僵局，等待线程异常退出。
最后1个类是使用最多的类，thread 创建线程对象，这个使用的最多。

二，线程安全与GLI
1. 在线程上还是要关注一下线程安全问题，因为多线程一定是有线程安全问题的，并不是所有的内置数据结构在多线程里都是线程安全的，比如说list，dict，set都不能保证线程安全问题，
这些容器如果不加锁，是无法准确的获取容器大小的，因为一个线程对其进行了修改，还没等拿回数据就有可能被另一个线程修改了。
pirnt语句也是线程不安全的，解决的方法可以用logging输出到日志中
但是Queue就没问题，比如FIFO的Queue和LIFO的栈，优先队列等这些都是线程安全的。因为内部是使用了Lock和condition，适用于多线程之间交换数据。

2. 在CPyhon中有一把大锁，GLI 叫全局解释器锁，这是一把进程级别的锁，在一个进程的多线程里都会受到这把锁的限制，GLI保证了CPython的进程中，只会有一个线程来执行字节码，
哪怕是多核CPU下，也只会允许一个CPU的一个线程执行。Python中大部分的读写操作都是原子性的，但是python的内置数据结构本身实质上又是线程不安全的，那么为什么在进行多线
程编程时感觉变的安全了，就是因为有GLI的存在，可以保证这些操作是安全的。
GLI的问题在IO密集型问题上并不明显，但是对于CPU密集型就会出现某一个线程因为争抢连续的获得GLI而导致其他线程无法使用CPU的效率问题。这种情况下可以使用多进程，每一个进程
开启一个线程，绕开GLI，这样就可以解决问题。所以在IO密集型情况中可以使用多线程，在CPU密集情况中可以使用多进程。


三，多线程：
1. daemon线程和non_daemon线程  主线程默认是non_daemon线程，daemon=False/True  未设置daemon时，子线程继承父线程。
不管是父线程还是子线程，线程中有non_daemon的线程，主线程就要等。
2. join(slef, timeout=None) 可以阻塞线程，timeout未设置时，无限等待，timeout设置时到了时间主线程结束，有join方法，设置daemon没有意义，因为阻塞了
t1.join()就要等t1结束，t2.join()就要等t2结束。总之谁join了就要等谁

四，进程
进程与线程用法很类似，线程的那些东西进程里面基本都有，比如说Event, Lock，Rlock，Condition, Barrier, Semaphore这些线程有的东西进程也有，也有不一样的。
Process类，创建一个进程对象，但是里面的API接口跟线程都是一样的，线程对象怎么创建进程对象就怎么创建。
Process().pid 返回进程的id
Process().exitcode 返回进程退出的状态码
Process().terminate() 终止指定的进程

进程池的使用
multiprocessing.Pool
p = multiprocessing.Pool(5)  --> 创建5个进程的进程池
p.apply(self, func, args=(), kwargs={})  阻塞执行，一个个顺着执行, args传一个元组，kwargs传一个字典
p.apply_async(self, func, args=(), kwargs={}, callback=None, error_callback=None)  与apply的用法一样，这个是非阻塞异步的，得到结果以后会回调
p.close() 关闭池，池不在接收新的任务
p.terminate() 结束进程，已经不在处理还没有处理到的任务
p.join() 主进程阻塞等待子进程的退出，这个方法要在close()或 terminate() 之后使用

例：
def fn(x):
    return x+1

if __name__ = '__main__':
    p = multiprocessing.Pool(10)
    for i in range(9):
        p.apply_async(fn, args=(1，)，callback=lambda x : logging.info('{} in callback'.format(x)))
   p.close()
   p.join()
 


















